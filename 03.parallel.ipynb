{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from utils import llm_call_async\n",
    "\n",
    "async def run_llm_parallel(prompt_details):\n",
    "    tasks = [llm_call_async(prompt['user_prompt'], prompt['model']) for prompt in prompt_details]\n",
    "    responses = []\n",
    "    \n",
    "    for task in asyncio.as_completed(tasks):\n",
    "        result = await task\n",
    "        print(\"LLM Answer Complete: \", result)\n",
    "        responses.append(result)\n",
    "        \n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def main():\n",
    "    question = (\"ì•„ë˜ ë¬¸ì¥ì„ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì¤˜:\\n\"\n",
    "                \"\\\"Do what you can, with what you have, where you are.\\\" â€” Theodore Roosevelt\")\n",
    "    \n",
    "    parallel_prompt_details = [\n",
    "        {\"user_prompt\": question, \"model\": \"gemini-1.5-flash\"},\n",
    "        {\"user_prompt\": question, \"model\": \"gemini-1.5-flash-8b\"},\n",
    "        {\"user_prompt\": question, \"model\": \"gemini-1.5-flash\"},\n",
    "    ]\n",
    "    \n",
    "    responses = await run_llm_parallel(parallel_prompt_details)\n",
    "    \n",
    "    aggregator_prompt = (\"ë‹¤ìŒì€ ì—¬ëŸ¬ ê°œì˜ AI ëª¨ë¸ì´ ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ ìƒì„±í•œ ì‘ë‹µì…ë‹ˆë‹¤.\\n\"\n",
    "                         \"ë‹¹ì‹ ì˜ ì—­í• ì€ ì´ ì‘ë‹µë“¤ì„ ëª¨ë‘ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\\n\"\n",
    "                         \"ì¼ë¶€ ì‘ë‹µì´ ë¶€ì •í™•í•˜ê±°ë‚˜ í¸í–¥ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì‹ ë¢°ì„±ê³¼ ì •í™•ì„±ì„ ê°–ì¶˜ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\\n\\n\"\n",
    "                         \"ì‚¬ìš©ì ì§ˆë¬¸:\\n\"\n",
    "                         f\"{question}\\n\\n\"\n",
    "                         \"ëª¨ë¸ ì‘ë‹µë“¤:\")\n",
    "    \n",
    "    for i in range(len(parallel_prompt_details)):\n",
    "        aggregator_prompt += f\"\\n{i+1}. ëª¨ë¸ ì‘ë‹µ: {responses[i]}\\n\"\n",
    "    \n",
    "    print(\"---------------------------ì¢…í•© í”„ë¡¬í”„íŠ¸:-----------------------\\n\", aggregator_prompt)\n",
    "    final_response = await llm_call_async(aggregator_prompt, model=\"gemini-1.5-pro-latest\")\n",
    "    print(\"---------------------------ìµœì¢… ì¢…í•© ì‘ë‹µ:-----------------------\\n\", final_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Answer Complete:  ë„¤ê°€ ìˆëŠ” ê³³ì—ì„œ, ë„¤ê°€ ê°€ì§„ ê²ƒìœ¼ë¡œ, ë„¤ê°€ í•  ìˆ˜ ìˆëŠ” ì¼ì„ í•˜ë¼.\n",
      "LLM Answer Complete:  ë„¤ê°€ ìˆëŠ” ê³³ì—ì„œ, ë„¤ê°€ ê°€ì§„ ê²ƒìœ¼ë¡œ, ë„¤ê°€ í•  ìˆ˜ ìˆëŠ” ê²ƒì„ í•˜ë¼.\n",
      "LLM Answer Complete:  ë„¤ê°€ ê°€ì§„ ê²ƒìœ¼ë¡œ, ë„¤ê°€ ìˆëŠ” ê³³ì—ì„œ, ë„¤ê°€ í•  ìˆ˜ ìˆëŠ” ë§Œí¼ í•´ë¼. â€” í…Œì˜¤ë„ë¥´ ë£¨ìŠ¤ë²¨íŠ¸\n",
      "---------------------------ì¢…í•© í”„ë¡¬í”„íŠ¸:-----------------------\n",
      " ë‹¤ìŒì€ ì—¬ëŸ¬ ê°œì˜ AI ëª¨ë¸ì´ ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ ìƒì„±í•œ ì‘ë‹µì…ë‹ˆë‹¤.\n",
      "ë‹¹ì‹ ì˜ ì—­í• ì€ ì´ ì‘ë‹µë“¤ì„ ëª¨ë‘ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
      "ì¼ë¶€ ì‘ë‹µì´ ë¶€ì •í™•í•˜ê±°ë‚˜ í¸í–¥ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì‹ ë¢°ì„±ê³¼ ì •í™•ì„±ì„ ê°–ì¶˜ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì‚¬ìš©ì ì§ˆë¬¸:\n",
      "ì•„ë˜ ë¬¸ì¥ì„ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì¤˜:\n",
      "\"Do what you can, with what you have, where you are.\" â€” Theodore Roosevelt\n",
      "\n",
      "ëª¨ë¸ ì‘ë‹µë“¤:\n",
      "1. ëª¨ë¸ ì‘ë‹µ: ë„¤ê°€ ìˆëŠ” ê³³ì—ì„œ, ë„¤ê°€ ê°€ì§„ ê²ƒìœ¼ë¡œ, ë„¤ê°€ í•  ìˆ˜ ìˆëŠ” ì¼ì„ í•˜ë¼.\n",
      "\n",
      "2. ëª¨ë¸ ì‘ë‹µ: ë„¤ê°€ ìˆëŠ” ê³³ì—ì„œ, ë„¤ê°€ ê°€ì§„ ê²ƒìœ¼ë¡œ, ë„¤ê°€ í•  ìˆ˜ ìˆëŠ” ê²ƒì„ í•˜ë¼.\n",
      "\n",
      "3. ëª¨ë¸ ì‘ë‹µ: ë„¤ê°€ ê°€ì§„ ê²ƒìœ¼ë¡œ, ë„¤ê°€ ìˆëŠ” ê³³ì—ì„œ, ë„¤ê°€ í•  ìˆ˜ ìˆëŠ” ë§Œí¼ í•´ë¼. â€” í…Œì˜¤ë„ë¥´ ë£¨ìŠ¤ë²¨íŠ¸\n",
      "\n",
      "---------------------------ìµœì¢… ì¢…í•© ì‘ë‹µ:-----------------------\n",
      " **ê°€ì§„ ê²ƒì„ ê°€ì§€ê³ , ìˆëŠ” ìë¦¬ì—ì„œ, í•  ìˆ˜ ìˆëŠ” ê²ƒì„ í•˜ë¼. - ì‹œì–´ë„ì–´ ë£¨ìŠ¤ë²¨íŠ¸**\n",
      "\n",
      "ì„¸ ê°€ì§€ ëª¨ë¸ ì‘ë‹µ ëª¨ë‘ í•µì‹¬ ë©”ì‹œì§€ë¥¼ ì˜ ì „ë‹¬í•˜ê³  ìˆì§€ë§Œ, ì•½ê°„ì”© ì–´ìƒ‰í•œ ë¶€ë¶„ì´ ìˆìŠµë‹ˆë‹¤.  \"ë„¤ê°€\"ë¼ëŠ” í‘œí˜„ì€ ë‹¤ì†Œ ë”±ë”±í•˜ê²Œ ëŠê»´ì§ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìƒëµí•˜ê³ , ì˜ë¯¸ë¥¼ ëª…í™•íˆ í•˜ê¸° ìœ„í•´ \"í•  ìˆ˜ ìˆëŠ” ë§Œí¼\"ë³´ë‹¤ëŠ” \"í•  ìˆ˜ ìˆëŠ” ê²ƒì„\"ì´ ë” ì ì ˆí•©ë‹ˆë‹¤.  ë˜í•œ, ì›ë¬¸ì˜ ê°„ê²°í•¨ê³¼ í˜ì„ ì‚´ë¦¬ê¸° ìœ„í•´ ì–´ìˆœì„ ì¡°ì •í•˜ê³ , ì¶œì²˜ë¥¼ ëª…í™•í•˜ê²Œ ë°íˆëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ë¹„ë™ê¸° main í•¨ìˆ˜ ì‹¤í–‰\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì¤‘...\n",
      "ë°ì´í„° ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "def fetch_data():\n",
    "    print(\"ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì¤‘...\")\n",
    "    time.sleep(2)\n",
    "    return \"ë°ì´í„° ë¡œë“œ ì™„ë£Œ\"\n",
    "\n",
    "def main():\n",
    "    result = fetch_data()\n",
    "    print(result)\n",
    "\n",
    "main()  # ë‹¤ë¥¸ ì‘ì—…ì„ ë³‘ë ¬ë¡œ ìˆ˜í–‰ ê°€ëŠ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì¤‘...\n",
      "ë°ì´í„° ë¡œë“œ ì™„ë£Œ\n",
      "ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì¤‘...\n",
      "ë°ì´í„° ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def fetch_data():\n",
    "    print(\"ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì¤‘...\")\n",
    "    await asyncio.sleep(2)\n",
    "    return \"ë°ì´í„° ë¡œë“œ ì™„ë£Œ\"\n",
    "\n",
    "async def main():\n",
    "    result = await fetch_data()\n",
    "    print(result)\n",
    "\n",
    "await main()  # ë‹¤ë¥¸ ì‘ì—…ì„ ë³‘ë ¬ë¡œ ìˆ˜í–‰ ê°€ëŠ¥\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‘ì—… 1 ì‹œì‘\n",
      "ì‘ì—… 2 ì‹œì‘\n",
      "ì‘ì—… 1 ì™„ë£Œ\n",
      "ì‘ì—… 2 ì™„ë£Œ\n",
      "ëª¨ë“  ì‘ì—… ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def task(name):\n",
    "    print(f\"{name} ì‹œì‘\")\n",
    "    time.sleep(2)\n",
    "    print(f\"{name} ì™„ë£Œ\")\n",
    "\n",
    "t1 = threading.Thread(target=task, args=(\"ì‘ì—… 1\",))\n",
    "t2 = threading.Thread(target=task, args=(\"ì‘ì—… 2\",))\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "print(\"ëª¨ë“  ì‘ì—… ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê°ì • ë¶„ì„ ê²°ê³¼: ê¸ì •ì  (ì…ë ¥: AI ê¸°ìˆ ì€ ì ì  ë°œì „í•˜ê³  ìˆìœ¼ë©°, ë§ì€ ì‚°ì—…ì—ì„œ í™œìš©ë˜ê³  ìˆë‹¤.)\n",
      "ìš”ì•½ ê²°ê³¼: AIëŠ” ë¯¸ë˜ì˜ í•µì‹¬ ê¸°ìˆ ì´ë‹¤. (ì…ë ¥: AI ê¸°ìˆ ì€ ì ì  ë°œì „í•˜ê³  ìˆìœ¼ë©°, ë§ì€ ì‚°ì—…ì—ì„œ í™œìš©ë˜ê³  ìˆë‹¤.)\n",
      "ë²ˆì—­ ê²°ê³¼: AI is the key technology of the future. (ì…ë ¥: AI ê¸°ìˆ ì€ ì ì  ë°œì „í•˜ê³  ìˆìœ¼ë©°, ë§ì€ ì‚°ì—…ì—ì„œ í™œìš©ë˜ê³  ìˆë‹¤.)\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import random\n",
    "\n",
    "async def sentiment_analysis(text):\n",
    "    \"\"\"ê°ì • ë¶„ì„ ì‹¤í–‰ (ë¹„ë™ê¸°)\"\"\"\n",
    "    await asyncio.sleep(random.uniform(1, 3))  # ì‹¤í–‰ ì‹œê°„ ëœë¤\n",
    "    return f\"ê°ì • ë¶„ì„ ê²°ê³¼: ê¸ì •ì  (ì…ë ¥: {text})\"\n",
    "\n",
    "async def summarization(text):\n",
    "    \"\"\"ìš”ì•½ ì‹¤í–‰ (ë¹„ë™ê¸°)\"\"\"\n",
    "    await asyncio.sleep(random.uniform(1, 3))\n",
    "    return f\"ìš”ì•½ ê²°ê³¼: AIëŠ” ë¯¸ë˜ì˜ í•µì‹¬ ê¸°ìˆ ì´ë‹¤. (ì…ë ¥: {text})\"\n",
    "\n",
    "async def translation(text):\n",
    "    \"\"\"ë²ˆì—­ ì‹¤í–‰ (ë¹„ë™ê¸°)\"\"\"\n",
    "    await asyncio.sleep(random.uniform(1, 3))\n",
    "    return f\"ë²ˆì—­ ê²°ê³¼: AI is the key technology of the future. (ì…ë ¥: {text})\"\n",
    "\n",
    "async def main():\n",
    "    text = \"AI ê¸°ìˆ ì€ ì ì  ë°œì „í•˜ê³  ìˆìœ¼ë©°, ë§ì€ ì‚°ì—…ì—ì„œ í™œìš©ë˜ê³  ìˆë‹¤.\"\n",
    "    \n",
    "    # ì—¬ëŸ¬ ê°œì˜ AI ì‘ì—…ì„ ë³‘ë ¬ ì‹¤í–‰\n",
    "    tasks = [\n",
    "        sentiment_analysis(text),\n",
    "        summarization(text),\n",
    "        translation(text)\n",
    "    ]\n",
    "    \n",
    "    results = await asyncio.gather(*tasks)  # ëª¨ë“  ì‘ì—…ì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°\n",
    "    for result in results:\n",
    "        print(result)\n",
    "\n",
    "# ì‹¤í–‰\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‘ì—… 1 ì‹œì‘ - 13:26:13\n",
      "ì‘ì—… 2 ì‹œì‘ - 13:26:13\n",
      "ì‘ì—… 3 ì‹œì‘ - 13:26:13\n",
      "ì‘ì—… 3 ì™„ë£Œ - 13:26:14\n",
      "ì‘ì—… 2 ì™„ë£Œ - 13:26:15\n",
      "ì‘ì—… 1 ì™„ë£Œ - 13:26:16\n",
      "\n",
      "ëª¨ë“  ì‘ì—… ì™„ë£Œ âœ…\n",
      "ì‘ì—… 1 ê²°ê³¼\n",
      "ì‘ì—… 2 ê²°ê³¼\n",
      "ì‘ì—… 3 ê²°ê³¼\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def task(name, delay):\n",
    "    \"\"\"ì§€ì •ëœ ì‹œê°„(delay) í›„ì— ì‘ì—…ì„ ì™„ë£Œí•˜ëŠ” ë¹„ë™ê¸° í•¨ìˆ˜\"\"\"\n",
    "    print(f\"{name} ì‹œì‘ - {time.strftime('%X')}\")\n",
    "    await asyncio.sleep(delay)  # ì§€ì •ëœ ì‹œê°„ ë™ì•ˆ ëŒ€ê¸° (ë¹„ë™ê¸° ì‹¤í–‰)\n",
    "    print(f\"{name} ì™„ë£Œ - {time.strftime('%X')}\")\n",
    "    return f\"{name} ê²°ê³¼\"\n",
    "\n",
    "async def main():\n",
    "    \"\"\"ì—¬ëŸ¬ ê°œì˜ ì‘ì—…ì„ ë™ì‹œì— ì‹¤í–‰\"\"\"\n",
    "    tasks = [\n",
    "        task(\"ì‘ì—… 1\", 3),\n",
    "        task(\"ì‘ì—… 2\", 2),\n",
    "        task(\"ì‘ì—… 3\", 1)\n",
    "    ]\n",
    "    \n",
    "    # ëª¨ë“  ì‘ì—…ì„ ë³‘ë ¬ ì‹¤í–‰\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    \n",
    "    print(\"\\nëª¨ë“  ì‘ì—… ì™„ë£Œ âœ…\")\n",
    "    for result in results:\n",
    "        print(result)\n",
    "\n",
    "# ì‹¤í–‰\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "async def sentiment_analysis(text: str):\n",
    "    \"\"\"ê°ì • ë¶„ì„ ì‹¤í–‰\"\"\"\n",
    "    delay = random.uniform(1, 3)  # 1~3ì´ˆ ëœë¤ ë”œë ˆì´\n",
    "    print(f\"ğŸ§  ê°ì • ë¶„ì„ ì‹œì‘ - {time.strftime('%X')}\")\n",
    "    await asyncio.sleep(delay)\n",
    "    print(f\"ğŸ§  ê°ì • ë¶„ì„ ì™„ë£Œ - {time.strftime('%X')}\")\n",
    "    return {\"task\": \"sentiment_analysis\", \"result\": \"ê¸ì •ì \"}\n",
    "\n",
    "async def summarization(text: str):\n",
    "    \"\"\"ìš”ì•½ ì‹¤í–‰\"\"\"\n",
    "    delay = random.uniform(1, 3)\n",
    "    print(f\"ğŸ“„ ìš”ì•½ ì‹œì‘ - {time.strftime('%X')}\")\n",
    "    await asyncio.sleep(delay)\n",
    "    print(f\"ğŸ“„ ìš”ì•½ ì™„ë£Œ - {time.strftime('%X')}\")\n",
    "    return {\"task\": \"summarization\", \"result\": \"AIëŠ” ë¯¸ë˜ì˜ í•µì‹¬ ê¸°ìˆ ì´ë‹¤.\"}\n",
    "\n",
    "async def translation(text: str):\n",
    "    \"\"\"ë²ˆì—­ ì‹¤í–‰\"\"\"\n",
    "    delay = random.uniform(1, 3)\n",
    "    print(f\"ğŸŒ ë²ˆì—­ ì‹œì‘ - {time.strftime('%X')}\")\n",
    "    await asyncio.sleep(delay)\n",
    "    print(f\"ğŸŒ ë²ˆì—­ ì™„ë£Œ - {time.strftime('%X')}\")\n",
    "    return {\"task\": \"translation\", \"result\": \"AI is the key technology of the future.\"}\n",
    "\n",
    "async def process_text(text: str):\n",
    "    \"\"\"ë¹„ë™ê¸°ì ìœ¼ë¡œ ê°ì • ë¶„ì„, ìš”ì•½, ë²ˆì—­ì„ ë™ì‹œì— ì‹¤í–‰\"\"\"\n",
    "    tasks = [\n",
    "        sentiment_analysis(text),\n",
    "        summarization(text),\n",
    "        translation(text)\n",
    "    ]\n",
    "\n",
    "    # ëª¨ë“  ì‘ì—…ì„ ë³‘ë ¬ ì‹¤í–‰\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    \n",
    "    return {\"status\": \"completed\", \"results\": results}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  ê°ì • ë¶„ì„ ì‹œì‘ - 13:30:02\n",
      "ğŸ“„ ìš”ì•½ ì‹œì‘ - 13:30:02\n",
      "ğŸŒ ë²ˆì—­ ì‹œì‘ - 13:30:02\n",
      "ğŸ“„ ìš”ì•½ ì™„ë£Œ - 13:30:04\n",
      "ğŸŒ ë²ˆì—­ ì™„ë£Œ - 13:30:05\n",
      "ğŸ§  ê°ì • ë¶„ì„ ì™„ë£Œ - 13:30:05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'completed',\n",
       " 'results': [{'task': 'sentiment_analysis', 'result': 'ê¸ì •ì '},\n",
       "  {'task': 'summarization', 'result': 'AIëŠ” ë¯¸ë˜ì˜ í•µì‹¬ ê¸°ìˆ ì´ë‹¤.'},\n",
       "  {'task': 'translation',\n",
       "   'result': 'AI is the key technology of the future.'}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await process_text(\"AI ê¸°ìˆ ì€ ë¯¸ë˜ë¥¼ ë°”ê¾¸ê³  ìˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
