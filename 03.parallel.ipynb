{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from utils import llm_call_async\n",
    "\n",
    "async def run_llm_parallel(prompt_details):\n",
    "    tasks = [llm_call_async(prompt['user_prompt'], prompt['model']) for prompt in prompt_details]\n",
    "    responses = []\n",
    "    \n",
    "    for task in asyncio.as_completed(tasks):\n",
    "        result = await task\n",
    "        print(\"LLM Answer Complete: \", result)\n",
    "        responses.append(result)\n",
    "        \n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def main():\n",
    "    question = (\"아래 문장을 자연스러운 한국어로 번역해줘:\\n\"\n",
    "                \"\\\"Do what you can, with what you have, where you are.\\\" — Theodore Roosevelt\")\n",
    "    \n",
    "    parallel_prompt_details = [\n",
    "        {\"user_prompt\": question, \"model\": \"gemini-1.5-flash\"},\n",
    "        {\"user_prompt\": question, \"model\": \"gemini-1.5-flash-8b\"},\n",
    "        {\"user_prompt\": question, \"model\": \"gemini-1.5-flash\"},\n",
    "    ]\n",
    "    \n",
    "    responses = await run_llm_parallel(parallel_prompt_details)\n",
    "    \n",
    "    aggregator_prompt = (\"다음은 여러 개의 AI 모델이 사용자 질문에 대해 생성한 응답입니다.\\n\"\n",
    "                         \"당신의 역할은 이 응답들을 모두 종합하여 최종 답변을 제공하는 것입니다.\\n\"\n",
    "                         \"일부 응답이 부정확하거나 편향될 수 있으므로, 신뢰성과 정확성을 갖춘 응답을 생성하는 것이 중요합니다.\\n\\n\"\n",
    "                         \"사용자 질문:\\n\"\n",
    "                         f\"{question}\\n\\n\"\n",
    "                         \"모델 응답들:\")\n",
    "    \n",
    "    for i in range(len(parallel_prompt_details)):\n",
    "        aggregator_prompt += f\"\\n{i+1}. 모델 응답: {responses[i]}\\n\"\n",
    "    \n",
    "    print(\"---------------------------종합 프롬프트:-----------------------\\n\", aggregator_prompt)\n",
    "    final_response = await llm_call_async(aggregator_prompt, model=\"gemini-1.5-pro-latest\")\n",
    "    print(\"---------------------------최종 종합 응답:-----------------------\\n\", final_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Answer Complete:  네가 있는 곳에서, 네가 가진 것으로, 네가 할 수 있는 일을 하라.\n",
      "LLM Answer Complete:  네가 있는 곳에서, 네가 가진 것으로, 네가 할 수 있는 것을 하라.\n",
      "LLM Answer Complete:  네가 가진 것으로, 네가 있는 곳에서, 네가 할 수 있는 만큼 해라. — 테오도르 루스벨트\n",
      "---------------------------종합 프롬프트:-----------------------\n",
      " 다음은 여러 개의 AI 모델이 사용자 질문에 대해 생성한 응답입니다.\n",
      "당신의 역할은 이 응답들을 모두 종합하여 최종 답변을 제공하는 것입니다.\n",
      "일부 응답이 부정확하거나 편향될 수 있으므로, 신뢰성과 정확성을 갖춘 응답을 생성하는 것이 중요합니다.\n",
      "\n",
      "사용자 질문:\n",
      "아래 문장을 자연스러운 한국어로 번역해줘:\n",
      "\"Do what you can, with what you have, where you are.\" — Theodore Roosevelt\n",
      "\n",
      "모델 응답들:\n",
      "1. 모델 응답: 네가 있는 곳에서, 네가 가진 것으로, 네가 할 수 있는 일을 하라.\n",
      "\n",
      "2. 모델 응답: 네가 있는 곳에서, 네가 가진 것으로, 네가 할 수 있는 것을 하라.\n",
      "\n",
      "3. 모델 응답: 네가 가진 것으로, 네가 있는 곳에서, 네가 할 수 있는 만큼 해라. — 테오도르 루스벨트\n",
      "\n",
      "---------------------------최종 종합 응답:-----------------------\n",
      " **가진 것을 가지고, 있는 자리에서, 할 수 있는 것을 하라. - 시어도어 루스벨트**\n",
      "\n",
      "세 가지 모델 응답 모두 핵심 메시지를 잘 전달하고 있지만, 약간씩 어색한 부분이 있습니다.  \"네가\"라는 표현은 다소 딱딱하게 느껴질 수 있으므로 생략하고, 의미를 명확히 하기 위해 \"할 수 있는 만큼\"보다는 \"할 수 있는 것을\"이 더 적절합니다.  또한, 원문의 간결함과 힘을 살리기 위해 어순을 조정하고, 출처를 명확하게 밝히는 것이 좋습니다.\n"
     ]
    }
   ],
   "source": [
    "# 비동기 main 함수 실행\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 가져오는 중...\n",
      "데이터 로드 완료\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "def fetch_data():\n",
    "    print(\"데이터 가져오는 중...\")\n",
    "    time.sleep(2)\n",
    "    return \"데이터 로드 완료\"\n",
    "\n",
    "def main():\n",
    "    result = fetch_data()\n",
    "    print(result)\n",
    "\n",
    "main()  # 다른 작업을 병렬로 수행 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 가져오는 중...\n",
      "데이터 로드 완료\n",
      "데이터 가져오는 중...\n",
      "데이터 로드 완료\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def fetch_data():\n",
    "    print(\"데이터 가져오는 중...\")\n",
    "    await asyncio.sleep(2)\n",
    "    return \"데이터 로드 완료\"\n",
    "\n",
    "async def main():\n",
    "    result = await fetch_data()\n",
    "    print(result)\n",
    "\n",
    "await main()  # 다른 작업을 병렬로 수행 가능\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "작업 1 시작\n",
      "작업 2 시작\n",
      "작업 1 완료\n",
      "작업 2 완료\n",
      "모든 작업 완료\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def task(name):\n",
    "    print(f\"{name} 시작\")\n",
    "    time.sleep(2)\n",
    "    print(f\"{name} 완료\")\n",
    "\n",
    "t1 = threading.Thread(target=task, args=(\"작업 1\",))\n",
    "t2 = threading.Thread(target=task, args=(\"작업 2\",))\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "print(\"모든 작업 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감정 분석 결과: 긍정적 (입력: AI 기술은 점점 발전하고 있으며, 많은 산업에서 활용되고 있다.)\n",
      "요약 결과: AI는 미래의 핵심 기술이다. (입력: AI 기술은 점점 발전하고 있으며, 많은 산업에서 활용되고 있다.)\n",
      "번역 결과: AI is the key technology of the future. (입력: AI 기술은 점점 발전하고 있으며, 많은 산업에서 활용되고 있다.)\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import random\n",
    "\n",
    "async def sentiment_analysis(text):\n",
    "    \"\"\"감정 분석 실행 (비동기)\"\"\"\n",
    "    await asyncio.sleep(random.uniform(1, 3))  # 실행 시간 랜덤\n",
    "    return f\"감정 분석 결과: 긍정적 (입력: {text})\"\n",
    "\n",
    "async def summarization(text):\n",
    "    \"\"\"요약 실행 (비동기)\"\"\"\n",
    "    await asyncio.sleep(random.uniform(1, 3))\n",
    "    return f\"요약 결과: AI는 미래의 핵심 기술이다. (입력: {text})\"\n",
    "\n",
    "async def translation(text):\n",
    "    \"\"\"번역 실행 (비동기)\"\"\"\n",
    "    await asyncio.sleep(random.uniform(1, 3))\n",
    "    return f\"번역 결과: AI is the key technology of the future. (입력: {text})\"\n",
    "\n",
    "async def main():\n",
    "    text = \"AI 기술은 점점 발전하고 있으며, 많은 산업에서 활용되고 있다.\"\n",
    "    \n",
    "    # 여러 개의 AI 작업을 병렬 실행\n",
    "    tasks = [\n",
    "        sentiment_analysis(text),\n",
    "        summarization(text),\n",
    "        translation(text)\n",
    "    ]\n",
    "    \n",
    "    results = await asyncio.gather(*tasks)  # 모든 작업이 끝날 때까지 대기\n",
    "    for result in results:\n",
    "        print(result)\n",
    "\n",
    "# 실행\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "작업 1 시작 - 13:26:13\n",
      "작업 2 시작 - 13:26:13\n",
      "작업 3 시작 - 13:26:13\n",
      "작업 3 완료 - 13:26:14\n",
      "작업 2 완료 - 13:26:15\n",
      "작업 1 완료 - 13:26:16\n",
      "\n",
      "모든 작업 완료 ✅\n",
      "작업 1 결과\n",
      "작업 2 결과\n",
      "작업 3 결과\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def task(name, delay):\n",
    "    \"\"\"지정된 시간(delay) 후에 작업을 완료하는 비동기 함수\"\"\"\n",
    "    print(f\"{name} 시작 - {time.strftime('%X')}\")\n",
    "    await asyncio.sleep(delay)  # 지정된 시간 동안 대기 (비동기 실행)\n",
    "    print(f\"{name} 완료 - {time.strftime('%X')}\")\n",
    "    return f\"{name} 결과\"\n",
    "\n",
    "async def main():\n",
    "    \"\"\"여러 개의 작업을 동시에 실행\"\"\"\n",
    "    tasks = [\n",
    "        task(\"작업 1\", 3),\n",
    "        task(\"작업 2\", 2),\n",
    "        task(\"작업 3\", 1)\n",
    "    ]\n",
    "    \n",
    "    # 모든 작업을 병렬 실행\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    \n",
    "    print(\"\\n모든 작업 완료 ✅\")\n",
    "    for result in results:\n",
    "        print(result)\n",
    "\n",
    "# 실행\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "async def sentiment_analysis(text: str):\n",
    "    \"\"\"감정 분석 실행\"\"\"\n",
    "    delay = random.uniform(1, 3)  # 1~3초 랜덤 딜레이\n",
    "    print(f\"🧠 감정 분석 시작 - {time.strftime('%X')}\")\n",
    "    await asyncio.sleep(delay)\n",
    "    print(f\"🧠 감정 분석 완료 - {time.strftime('%X')}\")\n",
    "    return {\"task\": \"sentiment_analysis\", \"result\": \"긍정적\"}\n",
    "\n",
    "async def summarization(text: str):\n",
    "    \"\"\"요약 실행\"\"\"\n",
    "    delay = random.uniform(1, 3)\n",
    "    print(f\"📄 요약 시작 - {time.strftime('%X')}\")\n",
    "    await asyncio.sleep(delay)\n",
    "    print(f\"📄 요약 완료 - {time.strftime('%X')}\")\n",
    "    return {\"task\": \"summarization\", \"result\": \"AI는 미래의 핵심 기술이다.\"}\n",
    "\n",
    "async def translation(text: str):\n",
    "    \"\"\"번역 실행\"\"\"\n",
    "    delay = random.uniform(1, 3)\n",
    "    print(f\"🌍 번역 시작 - {time.strftime('%X')}\")\n",
    "    await asyncio.sleep(delay)\n",
    "    print(f\"🌍 번역 완료 - {time.strftime('%X')}\")\n",
    "    return {\"task\": \"translation\", \"result\": \"AI is the key technology of the future.\"}\n",
    "\n",
    "async def process_text(text: str):\n",
    "    \"\"\"비동기적으로 감정 분석, 요약, 번역을 동시에 실행\"\"\"\n",
    "    tasks = [\n",
    "        sentiment_analysis(text),\n",
    "        summarization(text),\n",
    "        translation(text)\n",
    "    ]\n",
    "\n",
    "    # 모든 작업을 병렬 실행\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    \n",
    "    return {\"status\": \"completed\", \"results\": results}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 감정 분석 시작 - 13:30:02\n",
      "📄 요약 시작 - 13:30:02\n",
      "🌍 번역 시작 - 13:30:02\n",
      "📄 요약 완료 - 13:30:04\n",
      "🌍 번역 완료 - 13:30:05\n",
      "🧠 감정 분석 완료 - 13:30:05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'completed',\n",
       " 'results': [{'task': 'sentiment_analysis', 'result': '긍정적'},\n",
       "  {'task': 'summarization', 'result': 'AI는 미래의 핵심 기술이다.'},\n",
       "  {'task': 'translation',\n",
       "   'result': 'AI is the key technology of the future.'}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await process_text(\"AI 기술은 미래를 바꾸고 있다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
